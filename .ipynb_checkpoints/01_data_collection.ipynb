{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743630c1",
   "metadata": {},
   "source": [
    "# 01 — Data Collection\n",
    "\n",
    "**Project:** Fentanyl Overdose Death (ODD) Analysis  \n",
    "**Author:** Mitchell Yorkey \n",
    "**Last Updated:** 2026-02-19  \n",
    "\n",
    "## Purpose\n",
    "This notebook pulls provisional drug overdose death counts from the CDC's Vital Statistics Rapid Release (VSRR) system. It uses the CDC's Socrata API as the primary source and falls back to a local CSV if the API is unavailable. A timestamped snapshot is saved to `data/raw/` for reproducibility.\n",
    "\n",
    "## Data Source\n",
    "- **Dataset:** VSRR Provisional Drug Overdose Death Counts  \n",
    "- **Publisher:** CDC / National Center for Health Statistics (NCHS)  \n",
    "- **URL:** https://data.cdc.gov/National-Center-for-Health-Statistics/VSRR-Provisional-Drug-Overdose-Death-Counts/xkb8-kh2a  \n",
    "- **API Endpoint:** `https://data.cdc.gov/resource/xkb8-kh2a.json`  \n",
    "- **Update Frequency:** Monthly (provisional, subject to revision)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49cdc5",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed854edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:      C:\\Users\\Mitch\\Documents\n",
      "Raw dir:   C:\\Users\\Mitch\\Documents\\data\\raw\n",
      "Processed: C:\\Users\\Mitch\\Documents\\data\\processed\n",
      "App token: set ✓\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# ── Paths ──────────────────────────────────────────────────────────────────\n",
    "ROOT = Path().resolve().parent  # assumes notebooks/ folder\n",
    "RAW_DIR = ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── API Config ─────────────────────────────────────────────────────────────\n",
    "DATASET_ID = \"xkb8-kh2a\"\n",
    "API_BASE = f\"https://data.cdc.gov/resource/{DATASET_ID}.json\"\n",
    "PAGE_SIZE = 50000\n",
    "APP_TOKEN = \"gyCKnDytuJigWWnFNtsPElXA5\"\n",
    "\n",
    "# ── Fallback CSV path ──────────────────────────────────────────────────────\n",
    "FALLBACK_CSV = RAW_DIR / \"vsrr_overdose_fallback.csv\"\n",
    "\n",
    "print(f\"Root:      {ROOT}\")\n",
    "print(f\"Raw dir:   {RAW_DIR}\")\n",
    "print(f\"Processed: {PROCESSED_DIR}\")\n",
    "print(f\"App token: set ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6eba52",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. API Pull Function (with Pagination)\n",
    "\n",
    "The CDC uses the **Socrata Open Data API (SODA)**. Results are paginated — we request 50,000 rows at a time and loop until the dataset is fully pulled. If the API fails for any reason, we fall back to a local CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_cdc_vsrr_api(app_token=None, page_size=50000):\n",
    "    \"\"\"\n",
    "    Pull all records from the CDC VSRR dataset via the Socrata API.\n",
    "    Handles pagination automatically.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    app_token : str or None\n",
    "        Socrata app token for higher rate limits.\n",
    "    page_size : int\n",
    "        Number of records per API request.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame or None\n",
    "        Full dataset, or None if the pull failed.\n",
    "    \"\"\"\n",
    "    headers = {\"X-App-Token\": app_token} if app_token else {}\n",
    "    all_records = []\n",
    "    offset = 0\n",
    "\n",
    "    print(\"Fetching from CDC Socrata API...\")\n",
    "\n",
    "    while True:\n",
    "        params = {\n",
    "            \"$limit\": page_size,\n",
    "            \"$offset\": offset,\n",
    "            \"$order\": \":id\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(API_BASE, headers=headers, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"  ✗ API request failed at offset {offset}: {e}\")\n",
    "            return None\n",
    "\n",
    "        batch = response.json()\n",
    "\n",
    "        if not batch:\n",
    "            break\n",
    "\n",
    "        all_records.extend(batch)\n",
    "        print(f\"  Fetched {len(all_records):,} records so far...\")\n",
    "\n",
    "        if len(batch) < page_size:\n",
    "            break\n",
    "\n",
    "        offset += page_size\n",
    "\n",
    "    if all_records:\n",
    "        print(f\"  ✓ API pull complete. Total records: {len(all_records):,}\")\n",
    "        return pd.DataFrame(all_records)\n",
    "    else:\n",
    "        print(\"  ✗ No records returned from API.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306b7d2",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Fallback: Load from Local CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e70569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fallback_csv(path):\n",
    "    \"\"\"\n",
    "    Load the manually downloaded CDC VSRR CSV as a fallback.\n",
    "\n",
    "    How to get this file manually:\n",
    "    1. Go to https://data.cdc.gov/National-Center-Health-Statistics/\n",
    "       VSRR-Provisional-Drug-Overdose-Death-Counts/xkb8-kh2a\n",
    "    2. Click Export → CSV\n",
    "    3. Save to data/raw/vsrr_overdose_fallback.csv\n",
    "    \"\"\"\n",
    "    if Path(path).exists():\n",
    "        print(f\"Loading fallback CSV from: {path}\")\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        print(f\"  ✓ Loaded {len(df):,} rows from CSV fallback.\")\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"  ✗ No fallback CSV found at {path}\")\n",
    "        print(\"    → Download manually from the CDC website and save to data/raw/vsrr_overdose_fallback.csv\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bc17c7",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Main Ingestion Logic — API with CSV Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Try API first ──────────────────────────────────────────────────────────\n",
    "df_raw = fetch_cdc_vsrr_api(app_token=APP_TOKEN)\n",
    "\n",
    "# ── Fall back to CSV if API failed ─────────────────────────────────────────\n",
    "if df_raw is None:\n",
    "    print(\"\\nFalling back to local CSV...\")\n",
    "    df_raw = load_fallback_csv(FALLBACK_CSV)\n",
    "\n",
    "if df_raw is None:\n",
    "    raise RuntimeError(\n",
    "        \"Both API and CSV fallback failed. \"\n",
    "        \"Check your internet connection or download the CSV manually.\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nDataset shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {df_raw.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e5fa3",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Save Raw Snapshot with Timestamp\n",
    "\n",
    "We save an exact snapshot of what we pulled. This is critical for reproducibility — \n",
    "CDC provisional data gets revised retroactively, so a dated snapshot lets you \n",
    "know exactly what you were working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6635142",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "snapshot_path = RAW_DIR / f\"vsrr_overdose_raw_{timestamp}.csv\"\n",
    "\n",
    "df_raw.to_csv(snapshot_path, index=False)\n",
    "print(f\"✓ Raw snapshot saved to: {snapshot_path}\")\n",
    "print(f\"  Rows: {len(df_raw):,} | Columns: {len(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a64f04",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Initial Inspection\n",
    "\n",
    "Before cleaning anything, just look at what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b407bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97feafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What states/jurisdictions are included?\n",
    "print(\"Unique states/jurisdictions:\")\n",
    "state_col_guess = next((c for c in df_raw.columns if 'state' in c.lower()), None)\n",
    "print(sorted(df_raw[state_col_guess].unique()) if state_col_guess else \"Could not detect state column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What indicator types exist?\n",
    "indicator_col_guess = next((c for c in df_raw.columns if 'indicator' in c.lower()), None)\n",
    "print(\"Unique indicators (cause-of-death categories):\")\n",
    "if indicator_col_guess:\n",
    "    for ind in sorted(df_raw[indicator_col_guess].unique()):\n",
    "        print(f\"  {ind}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ed4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date range and null check\n",
    "print(\"Year range:\", df_raw['year'].unique() if 'year' in df_raw.columns else 'see columns above')\n",
    "print(\"\\nNull counts per column:\")\n",
    "print(df_raw.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de85c6",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Light Cleaning & Save to Processed\n",
    "\n",
    "Minimal cleaning here — type casting and column standardization only. \n",
    "Deeper analytical filtering happens in `02_eda_national_trend.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# ── Standardize column names to snake_case ─────────────────────────────────\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(\" \", \"_\")\n",
    "    .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    ")\n",
    "\n",
    "print(\"Cleaned column names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38821269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Cast types ─────────────────────────────────────────────────────────────\n",
    "# 'data_value' contains suppressed values marked as 'Suppressed' or 'Missing'\n",
    "# for small counts — coerce these to NaN.\n",
    "\n",
    "count_col = next((c for c in df.columns if 'data_value' in c or 'death' in c), None)\n",
    "print(f\"Death count column identified as: '{count_col}'\")\n",
    "\n",
    "if count_col:\n",
    "    df[count_col] = pd.to_numeric(df[count_col], errors='coerce')\n",
    "\n",
    "if 'year' in df.columns:\n",
    "    df['year'] = pd.to_numeric(df['year'], errors='coerce').astype('Int64')\n",
    "\n",
    "if 'month' in df.columns:\n",
    "    df['month'] = df['month'].astype(str).str.strip()\n",
    "\n",
    "# Create a proper date column for time series plotting\n",
    "if 'year' in df.columns and 'month' in df.columns:\n",
    "    df['date'] = pd.to_datetime(\n",
    "        df['year'].astype(str) + '-' + df['month'].str[:3],\n",
    "        format='%Y-%b',\n",
    "        errors='coerce'\n",
    "    )\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46121b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Save processed file ────────────────────────────────────────────────────\n",
    "processed_path = PROCESSED_DIR / f\"vsrr_overdose_processed_{timestamp}.csv\"\n",
    "df.to_csv(processed_path, index=False)\n",
    "print(f\"✓ Processed data saved to: {processed_path}\")\n",
    "\n",
    "# Also save a 'latest' version so downstream notebooks don't need a hardcoded date\n",
    "latest_path = PROCESSED_DIR / \"vsrr_overdose_latest.csv\"\n",
    "df.to_csv(latest_path, index=False)\n",
    "print(f\"✓ Also saved as: {latest_path} (overwritten on each pull)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6106b3d",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Quick Sanity Check — National Synthetic Opioid Deaths\n",
    "\n",
    "Filter to synthetic opioid deaths at the national level and confirm \n",
    "we can see the rise-and-fall shape described in Vangelov et al. (2026).\n",
    "\n",
    "> The article reports fentanyl ODDs peaking at **76,000 in 2023** and \n",
    "> dropping by over a third by end of 2024. We should see that shape here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0691a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "state_col = next((c for c in df.columns if 'state' in c), None)\n",
    "indicator_col = next((c for c in df.columns if 'indicator' in c), None)\n",
    "\n",
    "print(f\"State column:     '{state_col}'\")\n",
    "print(f\"Indicator column: '{indicator_col}'\")\n",
    "\n",
    "mask = (\n",
    "    (df[state_col].str.contains(\"United States\", na=False)) &\n",
    "    (df[indicator_col].str.contains(\"Synthetic opioids\", na=False))\n",
    ")\n",
    "df_national_synth = df[mask].copy()\n",
    "df_national_synth = df_national_synth.sort_values('date').dropna(subset=['date', count_col])\n",
    "\n",
    "print(f\"\\nRows matching filter: {len(df_national_synth)}\")\n",
    "df_national_synth[['date', count_col]].tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.plot(\n",
    "    df_national_synth['date'],\n",
    "    df_national_synth[count_col],\n",
    "    color='#c0392b',\n",
    "    linewidth=2,\n",
    "    label='Synthetic Opioid Deaths (provisional)'\n",
    ")\n",
    "\n",
    "ax.axvline(\n",
    "    pd.Timestamp('2023-05-01'),\n",
    "    color='gray', linestyle='--', alpha=0.7,\n",
    "    label='May 2023 peak (Vangelov et al.)'\n",
    ")\n",
    "\n",
    "ax.set_title('US Provisional Synthetic Opioid Overdose Deaths Over Time', fontsize=14)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Death Count (provisional)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = ROOT / \"outputs\" / \"figures\" / \"01_sanity_check_national_trend.png\"\n",
    "fig_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_path, dpi=150)\n",
    "print(f\"✓ Figure saved to: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953fcbfb",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Session Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 55)\n",
    "print(\"DATA COLLECTION SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"Run date:          {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"Source:            CDC VSRR API (xkb8-kh2a)\")\n",
    "print(f\"Total rows pulled: {len(df):,}\")\n",
    "print(f\"Date range:        {df['date'].min().date()} to {df['date'].max().date()}\")\n",
    "print(f\"Raw snapshot:      {snapshot_path.name}\")\n",
    "print(f\"Processed file:    {processed_path.name}\")\n",
    "print(\"\")\n",
    "print(\"Next step → 02_eda_national_trend.ipynb\")\n",
    "print(\"=\" * 55)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
